# Agentic Marketing Platform - PoC

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)

> **Production-ready multi-agent system for generating brand-aligned LinkedIn content with LLM-powered critique and RAG-based brand voice.**

---

## ğŸ¯ Overview

This Proof-of-Concept demonstrates a scalable agentic architecture for automated content generation. The system uses a **multi-agent workflow** where specialized AI agents collaborate to plan, write, and critique LinkedIn posts while maintaining strict brand voice adherence.

### Key Features

- **ğŸ¤– Multi-Agent Workflow**: Planner â†’ Writer â†’ Critic agents working in sequence
- **ğŸ¨ Brand Voice RAG**: Retrieval-Augmented Generation for consistent brand identity
- **ğŸ”„ Self-Critique Loop**: Automatic rewriting based on quality feedback (configurable threshold)
- **ğŸ“Š HTML Reporting**: Beautiful timeline reports of agent reasoning and decisions
- **ğŸš€ Inference Gateway**: Unified LLM interface with token tracking and mock support
- **ğŸ³ Docker-Ready**: Full containerization with Docker Compose
- **âœ… LLM-as-a-Judge**: Automated quality evaluation pipeline

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FastAPI Application                      â”‚
â”‚                    (Port 8000)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Marketing Agent            â”‚
         â”‚   (Orchestrator)             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚             â”‚             â”‚
      â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Planner  â”‚  â”‚  Writer  â”‚  â”‚ Critique â”‚
â”‚  Agent   â”‚â”€>â”‚  Agent   â”‚â”€>â”‚  Agent   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                   â”‚             â”‚
                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ (Rewrite Loop)
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Inference Gateway  â”‚
              â”‚  (LLM Abstraction) â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼               â–¼               â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ OpenAI  â”‚    â”‚   Mock   â”‚    â”‚ ChromaDB â”‚
  â”‚  API    â”‚    â”‚  Model   â”‚    â”‚ (Memory) â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Data Flow:**
1. User provides topic + brand ID
2. **PlannerAgent** creates structured outline
3. **WriterAgent** generates post with brand voice
4. **CritiqueAgent** evaluates quality (score 0-10)
5. If score < threshold: Writer rewrites (max 2 rewrites)
6. System returns final post + metadata

---

## ğŸ“ Project Structure

```
Marketing-Agent-Demo/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ gateway/                  # Inference Gateway (LLM abstraction)
â”‚   â”‚   â”œâ”€â”€ inference_gateway.py  # Main gateway logic
â”‚   â”‚   â””â”€â”€ models.py             # Pydantic models
â”‚   â”œâ”€â”€ agents/                   # Agent implementations
â”‚   â”‚   â””â”€â”€ marketing/            # Marketing agent module
â”‚   â”‚       â”œâ”€â”€ agent.py          # Orchestrator
â”‚   â”‚       â”œâ”€â”€ planner_agent.py  # Outline generation
â”‚   â”‚       â”œâ”€â”€ writer_agent.py   # Content creation
â”‚   â”‚       â”œâ”€â”€ critique_agent.py # Quality evaluation
â”‚   â”‚       â”œâ”€â”€ multi_agent_flow.py # Workflow coordinator
â”‚   â”‚       â”œâ”€â”€ brand_voice.py    # RAG for brand guidelines
â”‚   â”‚       â”œâ”€â”€ tools.py          # Agent tools
â”‚   â”‚       â”œâ”€â”€ models.py         # Data models
â”‚   â”‚       â””â”€â”€ api.py            # FastAPI endpoints
â”‚   â””â”€â”€ shared/                   # Shared utilities
â”‚       â”œâ”€â”€ config.py             # Configuration (12-factor)
â”‚       â”œâ”€â”€ logger.py             # Structured logging
â”‚       â”œâ”€â”€ database.py           # ChromaDB wrapper
â”‚       â”œâ”€â”€ trace_logger.py       # Agent execution tracking
â”‚       â””â”€â”€ html_reporter.py      # Report generation
â”‚
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ unit/                     # Unit tests
â”‚   â””â”€â”€ evaluation/               # LLM-as-a-Judge
â”‚       â””â”€â”€ evaluate_agent.py
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ specs/                    # Technical specifications
â”‚   â”œâ”€â”€ guides/                   # User guides
â”‚   â””â”€â”€ internal/                 # Development logs
â”‚
â”œâ”€â”€ examples/                     # Usage examples
â”‚   â”œâ”€â”€ direct_agent.py           # Direct agent usage
â”‚   â”œâ”€â”€ api_usage.py              # API client example
â”‚   â””â”€â”€ multi_agent_demo.py       # Multi-agent demo
â”‚
â”œâ”€â”€ knowledge_base/               # Brand voice guidelines
â”‚   â”œâ”€â”€ techcorp_brand_voice.txt
â”‚   â”œâ”€â”€ ecolife_brand_voice.txt
â”‚   â””â”€â”€ financewise_brand_voice.txt
â”‚
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ run.py                    # Application runner
â”‚   â”œâ”€â”€ dev.py                    # Development helper
â”‚   â””â”€â”€ verify_project.py         # Structure verification
â”‚
â”œâ”€â”€ .github/workflows/            # CI/CD pipeline
â”‚   â””â”€â”€ ci-cd.yml                 # GitHub Actions
â”‚
â”œâ”€â”€ docker-compose.yml            # Docker Compose configuration
â”œâ”€â”€ Dockerfile                    # Container definition
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ pyproject.toml                # Project metadata
â”œâ”€â”€ .env.example                  # Environment template
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ LICENSE                       # MIT License
â”œâ”€â”€ CONTRIBUTING.md               # Contribution guidelines
â””â”€â”€ README.md                     # This file
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Docker & Docker Compose** (recommended)
- **Git**

### Option 1: Docker (Recommended)

```bash
# 1. Clone the repository
git clone https://github.com/97anderson/Marketing-Agent-Demo.git
cd Marketing-Agent-Demo

# 2. Copy environment template
cp .env.example .env

# 3. Start services
docker-compose up --build

# 4. Access the API
curl http://localhost:8000/health
```

**The API will be available at:** `http://localhost:8000`  
**Interactive docs:** `http://localhost:8000/docs`

### Option 2: Local Development

```bash
# 1. Clone and setup
git clone https://github.com/97anderson/Marketing-Agent-Demo.git
cd Marketing-Agent-Demo

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Setup environment
cp .env.example .env
# Edit .env with your settings

# 5. Run the application
python scripts/run.py

# Or use the dev helper
python scripts/dev.py run
```

---

## ğŸ’¡ Usage Examples

### Generate a LinkedIn Post via API

```bash
curl -X POST http://localhost:8000/generate \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "The future of AI in software development",
    "tone": "professional",
    "brand_id": "techcorp"
  }'
```

**Response:**
```json
{
  "post": {
    "id": "uuid-here",
    "topic": "The future of AI in software development",
    "content": "ğŸš€ AI is transforming how we build software...",
    "tone": "professional",
    "brand_id": "techcorp",
    "metadata": {
      "workflow": "multi-agent",
      "iterations": 2,
      "final_score": 8.5,
      "workflow_summary": "[...]"
    }
  },
  "message": "Post generated successfully"
}
```

### Direct Agent Usage (Python)

```python
import asyncio
from src.agents.marketing.agent import MarketingAgent
from src.gateway.inference_gateway import InferenceGateway

async def main():
    gateway = InferenceGateway.from_settings()
    agent = MarketingAgent(gateway)
    
    result = await agent.generate_post(
        topic="Sustainable tech practices",
        tone="inspirational",
        brand_id="ecolife"
    )
    
    print(f"Generated Post:\n{result.content}")
    print(f"Score: {result.metadata['final_score']}")
    print(f"Iterations: {result.metadata['iterations']}")

asyncio.run(main())
```

### View Execution Report

```bash
# Generate a post and download the HTML report
curl -o report.html http://localhost:8000/report/download

# Open in browser
open report.html  # macOS
start report.html # Windows
xdg-open report.html # Linux
```

---

## ğŸ¨ Brand Voice System

The platform uses **RAG (Retrieval-Augmented Generation)** to maintain consistent brand identity:

1. **Add Brand Guidelines:** Create a `.txt` file in `knowledge_base/`
2. **Use in Requests:** Pass `brand_id` parameter (filename without extension)
3. **Automatic Injection:** System loads guidelines and injects into LLM prompts
4. **Critic Validation:** CritiqueAgent verifies brand adherence

**Example Brand File** (`knowledge_base/mycompany_brand_voice.txt`):
```
Brand Name: MyCompany
Voice: Professional yet approachable
Tone: Confident, data-driven
Key Phrases: "innovation-first", "customer-centric"
Hashtags: #MyCompanyInnovation #TechLeadership
```

**Usage:**
```bash
curl -X POST http://localhost:8000/generate \
  -d '{"topic": "...", "brand_id": "mycompany"}'
```

---

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `ENVIRONMENT` | Environment (development/production) | `development` |
| `USE_MOCK_MODEL` | Use mock LLM instead of OpenAI | `true` |
| `OPENAI_API_KEY` | OpenAI API key | `mock` |
| `USE_MULTI_AGENT_FLOW` | Enable multi-agent workflow | `true` |
| `CRITIQUE_THRESHOLD` | Minimum score to approve (0-10) | `8.0` |
| `MAX_REWRITES` | Maximum rewrite attempts | `2` |
| `API_HOST` | API host | `0.0.0.0` |
| `API_PORT` | API port | `8000` |

### Switching to Real OpenAI

1. Get an API key from [OpenAI](https://platform.openai.com/)
2. Update `.env`:
   ```bash
   USE_MOCK_MODEL=false
   OPENAI_API_KEY=sk-your-actual-key-here
   ```
3. Restart the application

---

## ğŸ§ª Development

### Run Tests

```bash
# All tests
python scripts/dev.py test

# With coverage report
pytest tests/ -v --cov=src --cov-report=html
open htmlcov/index.html
```

### Code Quality

```bash
# Lint
python scripts/dev.py lint

# Format
python scripts/dev.py format

# Full check
ruff check src/ tests/ && ruff format src/ tests/
```

### LLM-as-a-Judge Evaluation

```bash
python scripts/dev.py evaluate

# Or directly
python tests/evaluation/evaluate_agent.py
```

---

## ğŸ“Š API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check + system status |
| `/generate` | POST | Generate LinkedIn post |
| `/report/download` | GET | Download HTML execution report |
| `/metrics` | GET | System metrics |
| `/brands` | GET | List available brands |
| `/docs` | GET | Interactive API documentation |

**Full API Documentation:** Visit `http://localhost:8000/docs` when running.

---

## ğŸ”¬ Advanced Features

### Multi-Agent Workflow

The system orchestrates three specialized agents:

1. **PlannerAgent**: Creates structured outlines with hooks, key points, CTAs
2. **WriterAgent**: Generates content following the outline and brand voice
3. **CritiqueAgent**: Evaluates quality on 3 dimensions (brand adherence, quality, tone)

**Workflow Logic:**
```python
outline = planner.create_outline(topic)
post = writer.write_post(outline, brand_voice)
approved, feedback, score = critique.evaluate(post)

while not approved and iterations < MAX_REWRITES:
    post = writer.rewrite(post, feedback)
    approved, feedback, score = critique.evaluate(post)

return post, metadata
```

### HTML Reporting

Every agent execution generates a visual timeline report showing:
- Agent decisions and reasoning
- Iteration history (initial write + rewrites)
- Quality scores per iteration
- Time and cost metrics
- Final approval decision

**Features:**
- Dark mode design (Tailwind CSS)
- Expandable step details
- Color-coded statuses
- Copy-paste friendly metadata

---

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.

### Development Workflow

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run tests and linting
5. Commit with conventional commits (`feat:`, `fix:`, `docs:`, etc.)
6. Push and create a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](./LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Built with [FastAPI](https://fastapi.tiangolo.com/)
- Powered by [LangChain](https://www.langchain.com/)
- Styled with [Tailwind CSS](https://tailwindcss.com/)
- Vector storage by [ChromaDB](https://www.trychroma.com/)

---

## ğŸ“š Documentation

- **Quick Start Guide:** [docs/guides/QUICKSTART.md](./docs/guides/QUICKSTART.md)
- **Brand Voice Setup:** [docs/guides/BRAND_VOICE_GUIDE.md](./docs/guides/BRAND_VOICE_GUIDE.md)
- **Multi-Agent System:** [docs/guides/MULTI_AGENT_GUIDE.md](./docs/guides/MULTI_AGENT_GUIDE.md)
- **HTML Reporting:** [docs/guides/HTML_REPORT_GUIDE.md](./docs/guides/HTML_REPORT_GUIDE.md)
- **Docker Guide:** [docs/guides/DOCKER_DEMO_GUIDE.md](./docs/guides/DOCKER_DEMO_GUIDE.md)
- **Architecture Spec:** [docs/specs/ARCHITECTURE_SPEC.md](./docs/specs/ARCHITECTURE_SPEC.md)

---

## ğŸ› Known Issues & Roadmap

- [ ] Add support for more LLM providers (Anthropic, Cohere)
- [ ] Implement streaming responses
- [ ] Add multi-language support
- [ ] Create web UI for content generation
- [ ] Add more sophisticated RAG (semantic search over brand docs)
- [ ] Implement agent memory/context preservation
- [ ] Add A/B testing for different agent prompts

---

## ğŸ“ Support

- **Issues:** [GitHub Issues](https://github.com/97anderson/Marketing-Agent-Demo/issues)
- **Discussions:** [GitHub Discussions](https://github.com/97anderson/Marketing-Agent-Demo/discussions)
- **Email:** your-email@example.com

---

<p align="center">
  By Anderson Jimenez - Solutions Architect and AI Developer
</p>

<p align="center">
  <sub>This is a Proof-of-Concept for demonstration purposes.</sub>
</p>
